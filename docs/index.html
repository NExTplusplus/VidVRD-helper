<!DOCTYPE html>
<html lang="en">
    <head>
        <meta http-equiv="content-type" content="text/html; charset=UTF-8">
        <meta charset="utf-8">
        <meta name="renderer" content="webkit">
        <title>ACM'MM 2020 Video Relation Understanding Challenge</title>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="ACM Multimedia'20 Grand Challenge">
        <base href="mm20-gdc/" />

        <link href="styles/bootstrap.min.css" rel="stylesheet">
        <link href="styles/common.css" rel="stylesheet">
    </head>

    <body data-spy="scroll" data-target=".navbar">
        <nav class="navbar navbar-default navbar-fixed-top">
            <div class="container">
                <!-- Brand and toggle get grouped for better mobile display -->
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse" aria-expanded="false">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <h2 class="navbar-brand hidden-xs hidden-sm" style="padding-top: 0px;padding-bottom: 0px;height: 30px;line-height: 35px">
                        <span class="logo">Video Relation Understanding</span>
                    </h2>
                    <h5 class="hidden-xs hidden-sm" style="margin-bottom: 0px">
                        <span style="color:#003d7c !important;">ACM Multimedia 2020 Grand Challenge</span>
                    </h5>
                    <h2 class="navbar-brand hidden-md hidden-lg">
                        <span class="logo">VRU Challenge</span>
                    </h2>
                </div>

                <div class="collapse navbar-collapse" id="navbar-collapse">
                    <ul class="nav navbar-nav navbar-right">
                        <li><a class="page-scroll" href="#introduction">Introduction</a></li>
                        <li><a class="page-scroll" href="#task">Tasks</a></li>
                        <li><a class="page-scroll" href="#participation">Participation</a></li>
                        <li><a class="page-scroll" href="#timeline">Timeline</a></li>
                        <li><a class="page-scroll" href="#contact">Contact</a></li>
                    </ul>
                </div>
            </div>
        </nav>

        <section id="news" class="scrollable-section">
            <div class="container">
                <h3>News</h3>
                <ul style="list-style-type:circle;">
                    <li>We are still working hardly on the website...</li>
                </ul>
            </div>
        </section>

        <section id="introduction" class="scrollable-section">
            <div class="container">
                <h3>Introduction</h3>
                <p>
                    For decades, researchers mainly evaluate multimedia systems according to a set of
                    application-driven tasks, such as the cross-modal retrieval and concept annotation etc.
                    Although the recent advance in computer vision has effectively boosted the
                    performance of multimedia systems on these tasks, a core question still cannot be explicitly
                    answered: Does the machine understand what is happening in a video, and can the results of the
                    analysis be interpretable by human users? Another way to look at the limitation is to evaluate
                    how many facts that the machine can recognize from a video.
                </p>
                <p>
                    Video Relation Understanding (VRU) Challenge
                    will encourage researchers to explore a key aspect of recognizing
                    facts from a video, that is relation understanding. In many AI and knowledge-based systems,
                    a fact is represented by a relation between a subject entity and an object entity (i.e.
                    &lt;subject,predicate,object&gt;), which forms the fundamental building block for high-level
                    inference and decision making tasks. The challenge is based on
                    <a href="https://xdshang.github.io/docs/vidor.html" style="color: #ff6600;">VidOR Dataset</a>,
                    a large-scale user-generated video dataset with objects and relations densly annotated.
                    Different from last year, 
                    this year's challenge will focus on the challenging task of visual relation detection to push the limits of relation understanding.
                </p>
            </div>
        </section>

        <section id="task" class="scrollable-section">
            <div class="container">
                <h3>Tasks</h3>
                <h4>
                    Main Task: Visual Relation Detection
                    <a href="task1.html" style="font-size: 14px;">[details]</a>
                </h4>
                <p>
                    Beyond recognizing object and action individually, this task is to detect relation triplets (i.e.
                    &lt;subject,predicate,object&gt;) of interest and spatio-temporally localize the subject and object of
                    each detected relation triplet using bounding-box trajectories. The categories of predicate
                    will also include spatial type in addition to the action type. For each testing video, we compute AP
                    to evaluate the detection performance and rank according to the mean AP over all testing videos.
                </p>
                <h4>
                    Optional Task: Video Object Detection
                    <a href="task2.html" style="font-size: 14px;">[details]</a>
                </h4>
                <p>
                    As the first step in relation understanding, the task is to detect objects of certain categories
                    and spatio-temporally localize each detected object using a bounding-box trajectory in videos.
                    For each object category, we compute Average Precision (AP) to evaluate the detection performance
                    and rank according to the mean AP over all categories.
                </p>
            </div>
        </section>

        <section id="participation" class="scrollable-section">
            <div class="container">
                <h3>Participation</h3>
                <p>
                    The challenge is a team-based contest. Each team can have one or more members, and an individual cannot
                    be a member of multiple teams in a task. Registration page will be available soon...
                </p>
                <p>
                    At the end of the challenge, all teams will be ranked based on the objective evaluation above.
                    The top three performing teams of each task will receive award certificates.
                    At the same time, by submitting a 4-page overview paper (plus 1-page reference) to ACM MM'20,
                    all accepted submissions are eligible for the conferenceâ€™s grand challenge award competition.
                </p>
            </div>
        </section>

        <section id="timeline" class="scrollable-section">
            <div class="container">
                <h3>Timeline</h3>
                <ul>
                    <li>March 10, 2020: Website ready; training and validation data available for download</li>
                    <li>April 29, 2020: Registration close; online submission and live evaluation server open</li>
                    <li>May 29, 2020: Testing videos open to registered participants for download</li>
                    <li>June 29, 2020, 23:59 AoE: Results submission close</li>
                    <li>July 1, 2020: Evaluation results announce on the website</li>
                    <li>July 8, 2020: Paper submission deadline</li>
                </ul>
            </div>
        </section>

        <section id="contact" class="scrollable-section">
            <div class="container">
                <h3>Organizers</h2>
                <div class="col-12">
                    <div class="row">
                        <div class="col-6 col-sm-4 section-column speaker">
                            <a href="https://xdshang.github.io/" target="_blank">
                            <div class="speaker-image">
                                <img src="assets/Shang-Xindi.png" class="img-responsive speaker-avatar" width="80%" height="auto">
                            </div>
                            <div class="speaker-meta">
                                <h4 class="speaker-name">Shang Xindi</h4>
                                <p class="speaker-affiliate">National University of Singapore</p>
                            </div>
                            </a>
                        </div>
            
                        <div class="col-6 col-sm-4 section-column speaker">
                            <a href="http://bio.duxy.me/" target="_blank">
                            <div class="speaker-image">
                                <img src="assets/Shang-Xindi.png" class="img-responsive speaker-avatar" width="80%" height="auto">
                            </div>
                            <div class="speaker-meta">
                                <h4 class="speaker-name">Du Xiaoyu</h4>
                                <p class="speaker-affiliate">National University of Singapore</p>
                            </div>
                            </a>
                        </div>
            
                        <div class="col-6 col-sm-4 section-column speaker">
                            <a href="https://software.nju.edu.cn/rentw/" target="_blank">
                            <div class="speaker-image">
                                <img src="assets/Shang-Xindi.png" class="img-responsive speaker-avatar" width="80%" height="auto">
                            </div>
                            <div class="speaker-meta">
                                <h4 class="speaker-name">Ren Tongwei</h4>
                                <p class="speaker-affiliate">Nanjing University</p>
                            </div>
                            </a>
                        </div>
            
                        <div class="col-6 col-sm-4 section-column speaker">
                            <a href="https://github.com/jonathanstaniforth" target="_blank">
                            <div class="speaker-image">
                                <img src="assets/Shang-Xindi.png" class="img-responsive speaker-avatar" width="80%" height="auto">
                            </div>
                            <div class="speaker-meta">
                                <h4 class="speaker-name">Jonathan Staniforth</h4>
                                <p class="speaker-affiliate">National University of Singapore</p>
                            </div>
                            </a>
                        </div>
            
                        <div class="col-6 col-sm-4 section-column speaker">
                            <div class="speaker-image">
                                <img src="assets/Shang-Xindi.png" class="img-responsive speaker-avatar" width="80%" height="auto">
                            </div>
                            <div class="speaker-meta">
                                <h4 class="speaker-name">Xiao Junbin</h4>
                                <p class="speaker-affiliate">National University of Singapore</p>
                            </div>
                            </a>
                        </div>
                        
                        <div class="col-6 col-sm-4 section-column speaker">
                            <a href="https://www.chuatatseng.com/" target="_blank">
                            <div class="speaker-image">
                                <img src="assets/Chua-TatSeng.png" class="img-responsive speaker-avatar" width="80%" height="auto">
                            </div>
                            <div class="speaker-meta">
                                <h4 class="speaker-name">Chua Tat-Seng</h4>
                                <p class="speaker-affiliate">National University of Singapore</p>
                            </div>
                            </a>
                        </div>
                    </div>
                </div>
                <br><br>
                <p>
                    For general information about the challenge, please contact:
                    <ul>
                        <li>Du Xiaoyu and Shang Xindi</li>
                    </ul>
                    For information about Task 1, please contact:
                    <ul>
                        <li>Shang Xindi and Ren Tongwei</li>
                    </ul>
                    For information about Task 2, please contact:
                    <ul>
                        <li>Xiao Junbin</li>
                    </ul>
                    For reporting issue on the submission/evaluation server, please contact:
                    <ul>
                        <li>Jonathan Staniforth</li>
                    </ul>
                </p>
            </div>
        </section>

        <section id="previous" class="scrollable-section">
            <div class="container">
                <h3>Previous Years</h3>
                <ul>
                    <li><a href="https://videorelation.nextcenter.org/mm19-gdc/" target="_blank">ACM Multimedia 2019 Grand Challenge</a></li>
                </ul>
            </div>
        </section>

        <footer class="footer" style="padding-top: 50px;">
            <div class="container">
                <hr>
                <p style="font-style: italic; text-align: center">
                    Copyright &copy; 2018-2020 NExT++ /
                    <a class="black" href="http://www.nextcenter.org/privacy-policy">Privacy Policy</a> /
                    <a class="black" href="http://www.nextcenter.org/terms-conditions">Terms &amp; Conditions</a>
                </p>
            </div>
        </footer>

        <script type="text/javascript" src="scripts/jquery-3.2.1.min.js"></script>
        <script type="text/javascript" src="scripts/bootstrap.min.js"></script>
        <script type="text/javascript" src="scripts/jquery.easing.min.js"></script>
        <script type="text/javascript" src="scripts/scrolling-nav.js"></script>
    </body>
</html>
